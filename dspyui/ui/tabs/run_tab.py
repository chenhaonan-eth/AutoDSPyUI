"""
Run Program Tab

INPUT:  dspyui.core.runner, dspyui.utils.file_ops, gradio, pandas
OUTPUT: create_run_tab() å‡½æ•°
POS:    è¿è¡Œç¨‹åº Tabï¼Œæä¾›å·²ç¼–è¯‘ç¨‹åºçš„äº¤äº’å¼æ¨ç†ç•Œé¢ï¼Œæ”¯æŒå•æ¡å’Œæ‰¹é‡æ¨ç†ã€å†å²è®°å½•

âš ï¸ ä¸€æ—¦æˆ‘è¢«æ›´æ–°ï¼ŒåŠ¡å¿…æ›´æ–°æˆ‘çš„å¼€å¤´æ³¨é‡Šï¼Œä»¥åŠæ‰€å±æ–‡ä»¶å¤¹çš„ README.md
"""

from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime
import tempfile
import os

import gradio as gr
import pandas as pd

from dspyui.core.runner import (
    load_program_metadata,
    generate_program_response,
    validate_csv_headers,
    run_batch_inference,
)
from dspyui.utils.file_ops import list_programs
from dspyui.i18n import t


# æœ€å¤§è¾“å…¥å­—æ®µæ•°é‡
MAX_INPUT_FIELDS = 10

# æœ€å¤§å†å²è®°å½•æ•°é‡
MAX_HISTORY_SIZE = 10


@dataclass
class InferenceHistoryItem:
    """
    æ¨ç†å†å²è®°å½•é¡¹ã€‚
    
    Attributes:
        timestamp: æ¨ç†æ‰§è¡Œæ—¶é—´
        program_id: ç¨‹åº ID
        inputs: è¾“å…¥å­—æ®µå€¼å­—å…¸
        outputs: è¾“å‡ºå­—æ®µå€¼å­—å…¸
    """
    timestamp: datetime
    program_id: str
    inputs: Dict[str, str]
    outputs: Dict[str, str]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "timestamp": self.timestamp.isoformat(),
            "program_id": self.program_id,
            "inputs": self.inputs,
            "outputs": self.outputs,
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "InferenceHistoryItem":
        """ä»å­—å…¸åˆ›å»ºå®ä¾‹"""
        return cls(
            timestamp=datetime.fromisoformat(data["timestamp"]),
            program_id=data["program_id"],
            inputs=data["inputs"],
            outputs=data["outputs"],
        )
    
    def format_display(self) -> str:
        """æ ¼å¼åŒ–ä¸ºæ˜¾ç¤ºå­—ç¬¦ä¸²"""
        time_str = self.timestamp.strftime("%H:%M:%S")
        input_preview = ", ".join(f"{k}={v[:20]}..." if len(v) > 20 else f"{k}={v}" 
                                   for k, v in list(self.inputs.items())[:2])
        return f"[{time_str}] {input_preview}"


def add_history_item(
    history: List[Dict[str, Any]],
    program_id: str,
    inputs: Dict[str, str],
    outputs: Dict[str, str],
) -> List[Dict[str, Any]]:
    """
    æ·»åŠ å†å²è®°å½•é¡¹ã€‚
    
    Args:
        history: å½“å‰å†å²è®°å½•åˆ—è¡¨
        program_id: ç¨‹åº ID
        inputs: è¾“å…¥å­—æ®µå€¼
        outputs: è¾“å‡ºå­—æ®µå€¼
        
    Returns:
        æ›´æ–°åçš„å†å²è®°å½•åˆ—è¡¨ï¼ˆæœ€å¤š MAX_HISTORY_SIZE æ¡ï¼‰
    
    Requirements: 5.1, 5.2
    """
    item = InferenceHistoryItem(
        timestamp=datetime.now(),
        program_id=program_id,
        inputs=inputs,
        outputs=outputs,
    )
    
    # æ·»åŠ åˆ°åˆ—è¡¨å¼€å¤´ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    new_history = [item.to_dict()] + history
    
    # é™åˆ¶æœ€å¤§æ•°é‡
    if len(new_history) > MAX_HISTORY_SIZE:
        new_history = new_history[:MAX_HISTORY_SIZE]
    
    return new_history


def get_history_choices(history: List[Dict[str, Any]]) -> List[Tuple[str, int]]:
    """
    è·å–å†å²è®°å½•çš„é€‰æ‹©åˆ—è¡¨ã€‚
    
    Args:
        history: å†å²è®°å½•åˆ—è¡¨
        
    Returns:
        (æ˜¾ç¤ºæ–‡æœ¬, ç´¢å¼•) å…ƒç»„åˆ—è¡¨
    """
    choices = []
    for i, item_dict in enumerate(history):
        item = InferenceHistoryItem.from_dict(item_dict)
        choices.append((item.format_display(), i))
    return choices


def clear_history() -> List[Dict[str, Any]]:
    """
    æ¸…ç©ºå†å²è®°å½•ã€‚
    
    Returns:
        ç©ºçš„å†å²è®°å½•åˆ—è¡¨
        
    Requirements: 5.4
    """
    return []


def create_run_tab() -> None:
    """
    åˆ›å»º Run Program Tabã€‚
    
    åŒ…å«ï¼š
    - ç¨‹åºé€‰æ‹©å™¨
    - ç¨‹åºä¿¡æ¯å±•ç¤ºåŒº
    - åŠ¨æ€è¾“å…¥å­—æ®µ
    - è¿è¡ŒæŒ‰é’®å’Œç»“æœå±•ç¤º
    - æ‰¹é‡å¤„ç†åŒºåŸŸ
    
    Requirements: 1.1, 1.2, 1.4, 2.1, 2.2, 2.3, 2.4, 2.5, 3.1-3.6, 4.1-4.5
    """
    with gr.TabItem(t("run.tab_title")):
        # === çŠ¶æ€å˜é‡ ===
        current_program_id = gr.State(None)
        current_metadata = gr.State(None)
        current_mode = gr.State("single")  # "single" or "batch"
        batch_result_df = gr.State(None)  # å­˜å‚¨æ‰¹é‡æ¨ç†ç»“æœ
        inference_history = gr.State([])  # å­˜å‚¨å†å²è®°å½•åˆ—è¡¨
        
        # === 1. æ ‡é¢˜ ===
        gr.Markdown(f"# {t('run.title')}")
        gr.Markdown(t("run.subtitle"))
        
        # === 2. ç¨‹åºé€‰æ‹©åŒºåŸŸ ===
        # åˆå§‹åŒ–æ—¶åŠ è½½ç¨‹åºåˆ—è¡¨
        initial_programs = list_programs()
        initial_choices = [
            f"{p['id']} - {p['signature']} (Score: {p['eval_score']})"
            for p in initial_programs
        ] if initial_programs else []
        
        with gr.Row():
            with gr.Column(scale=3):
                program_dropdown = gr.Dropdown(
                    label=t("run.select_program"),
                    choices=initial_choices,
                    value=None,
                    interactive=True,
                    allow_custom_value=False,
                )
            with gr.Column(scale=1):
                refresh_btn = gr.Button(
                    t("run.refresh_programs"),
                    size="sm",
                )
        
        # === 3. ç¨‹åºä¿¡æ¯å±•ç¤ºåŒºåŸŸ ===
        with gr.Group(visible=False) as program_info_group:
            gr.Markdown(f"### {t('run.program_info.title')}")
            
            with gr.Row():
                signature_display = gr.Textbox(
                    label=t("run.program_info.signature"),
                    interactive=False,
                )
                model_display = gr.Textbox(
                    label=t("run.program_info.model"),
                    interactive=False,
                )
                module_display = gr.Textbox(
                    label=t("run.program_info.module"),
                    interactive=False,
                )
            
            with gr.Row():
                teacher_display = gr.Textbox(
                    label=t("run.program_info.teacher_model"),
                    interactive=False,
                )
                optimizer_display = gr.Textbox(
                    label=t("run.program_info.optimizer"),
                    interactive=False,
                )
            
            with gr.Row():
                eval_score_display = gr.Number(
                    label=t("run.program_info.evaluation_score"),
                    interactive=False,
                )
                baseline_score_display = gr.Number(
                    label=t("run.program_info.baseline_score"),
                    interactive=False,
                )
            
            instructions_display = gr.Textbox(
                label=t("run.program_info.instructions"),
                interactive=False,
                lines=2,
            )
            
            # å¯å±•å¼€çš„ä¼˜åŒ–æç¤ºè¯åŒºåŸŸ
            with gr.Accordion(
                t("run.program_info.view_prompt"),
                open=False,
            ):
                optimized_prompt_display = gr.Textbox(
                    label=t("run.program_info.optimized_prompt"),
                    interactive=False,
                    lines=15,
                    elem_classes=["optimized-prompt-textbox"],
                )
        
        # === 4. è¾“å…¥åŒºåŸŸ ===
        with gr.Group(visible=False) as input_section_group:
            gr.Markdown(f"### {t('run.input_section.title')}")
            gr.Markdown(t("run.input_section.description"))
            
            # å›ºå®šæ•°é‡çš„è¾“å…¥å­—æ®µæ§½ä½
            input_fields: List[Tuple[gr.Group, gr.Textbox]] = []
            for i in range(MAX_INPUT_FIELDS):
                with gr.Group(visible=False) as input_group:
                    input_textbox = gr.Textbox(
                        label=f"Input {i+1}",
                        placeholder="",
                        interactive=True,
                        lines=2,
                    )
                input_fields.append((input_group, input_textbox))
        
        # === 5. è¿è¡ŒæŒ‰é’®å’Œè¾“å‡ºåŒºåŸŸ ===
        with gr.Group(visible=False) as output_section_group:
            with gr.Row():
                run_btn = gr.Button(
                    t("run.buttons.run"),
                    variant="primary",
                    scale=1,
                )
                clear_btn = gr.Button(
                    t("run.buttons.clear"),
                    scale=1,
                )
            
            # åŠ è½½çŠ¶æ€æŒ‡ç¤ºå™¨
            loading_indicator = gr.Markdown(
                value=f"â³ {t('run.loading.inference')}",
                visible=False,
            )
            
            gr.Markdown(f"### {t('run.output_section.title')}")
            
            output_display = gr.Textbox(
                label=t("run.output_section.description"),
                interactive=False,
                lines=10,
                max_lines=20,
            )
            
            error_display = gr.Markdown(visible=False)
        
        # === 6. æ¨¡å¼åˆ‡æ¢å’Œæ‰¹é‡å¤„ç†åŒºåŸŸ ===
        with gr.Group(visible=False) as batch_section_group:
            gr.Markdown(f"### {t('run.batch.title')}")
            
            # æ¨¡å¼åˆ‡æ¢æŒ‰é’®
            with gr.Row():
                mode_toggle_btn = gr.Button(
                    t("run.mode.switch_to_batch"),
                    variant="secondary",
                    scale=1,
                )
            
            # æ‰¹é‡å¤„ç†åŒºåŸŸ (åˆå§‹éšè—)
            with gr.Group(visible=False) as batch_upload_group:
                # æ˜¾ç¤ºæœŸæœ›çš„åˆ—å
                expected_headers_display = gr.Textbox(
                    label=t("run.batch.expected_headers"),
                    interactive=False,
                    lines=1,
                )
                
                # CSV ä¸Šä¼ ç»„ä»¶
                csv_upload = gr.File(
                    label=t("run.batch.upload_csv"),
                    file_types=[".csv"],
                    type="filepath",
                )
                
                # CSV éªŒè¯çŠ¶æ€æ˜¾ç¤º
                csv_validation_status = gr.Markdown(visible=False)
                
                # å¼€å§‹æ‰¹é‡æ¨ç†æŒ‰é’®
                start_batch_btn = gr.Button(
                    t("run.batch.start_batch"),
                    variant="primary",
                    interactive=False,
                )
                
                # è¿›åº¦æ˜¾ç¤º
                batch_progress = gr.Markdown(
                    value="",
                    visible=False,
                )
                
                # ç»“æœé¢„è§ˆè¡¨æ ¼
                batch_results_table = gr.Dataframe(
                    label=t("run.batch.results_preview"),
                    visible=False,
                    interactive=False,
                )
                
                # å¯¼å‡ºæŒ‰é’®å’Œä¸‹è½½ç»„ä»¶
                with gr.Row(visible=False) as export_row:
                    export_btn = gr.Button(
                        t("run.batch.export_results"),
                        variant="secondary",
                    )
                    download_file = gr.File(
                        label=t("run.batch.download_csv"),
                        visible=False,
                    )
        
        # === 7. å†å²è®°å½•åŒºåŸŸ ===
        with gr.Group(visible=False) as history_section_group:
            gr.Markdown(f"### {t('run.history.title')}")
            gr.Markdown(t("run.history.description"))
            
            # å†å²è®°å½•åˆ—è¡¨
            history_list = gr.Dropdown(
                label=t("run.history.click_to_restore"),
                choices=[],
                value=None,
                interactive=True,
                allow_custom_value=False,
            )
            
            # æ¸…ç©ºå†å²æŒ‰é’®
            clear_history_btn = gr.Button(
                t("run.history.clear"),
                variant="secondary",
                size="sm",
            )
            
            # ç©ºå†å²æç¤º
            history_empty_msg = gr.Markdown(
                value=f"ğŸ“­ {t('run.history.empty')}",
                visible=True,
            )
        
        # === äº‹ä»¶å¤„ç†å‡½æ•° ===
        
        def refresh_program_list() -> Dict[str, Any]:
            """åˆ·æ–°ç¨‹åºåˆ—è¡¨"""
            programs = list_programs()
            if not programs:
                return gr.update(
                    choices=[],
                    value=None,
                    info=t("run.no_programs_available"),
                )
            
            # æ„å»ºé€‰é¡¹åˆ—è¡¨: "ID - Signature (Score: X)"
            choices = [
                f"{p['id']} - {p['signature']} (Score: {p['eval_score']})"
                for p in programs
            ]
            return gr.update(choices=choices, value=None)
        
        def on_program_select(
            selection: Optional[str],
        ) -> Tuple[Any, ...]:
            """
            å½“ç”¨æˆ·é€‰æ‹©ç¨‹åºæ—¶åŠ è½½å…ƒæ•°æ®å¹¶æ›´æ–° UIã€‚
            
            Returns:
                æ›´æ–°æ‰€æœ‰ç›¸å…³ç»„ä»¶çš„å…ƒç»„
            """
            if not selection:
                # éšè—æ‰€æœ‰åŒºåŸŸ
                updates = [
                    None,  # current_program_id
                    None,  # current_metadata
                    gr.update(visible=False),  # program_info_group
                    gr.update(visible=False),  # input_section_group
                    gr.update(visible=False),  # output_section_group
                    "",  # signature_display
                    "",  # model_display
                    "",  # module_display
                    "",  # teacher_display
                    "",  # optimizer_display
                    0.0,  # eval_score_display
                    0.0,  # baseline_score_display
                    "",  # instructions_display
                    "",  # optimized_prompt_display
                ]
                # éšè—æ‰€æœ‰è¾“å…¥å­—æ®µ
                for _ in range(MAX_INPUT_FIELDS):
                    updates.append(gr.update(visible=False))  # input_group
                    updates.append(gr.update(value="", label=""))  # input_textbox
                
                return tuple(updates)
            
            # ä»é€‰æ‹©ä¸­æå–ç¨‹åº ID
            program_id = selection.split(" - ")[0]
            
            try:
                metadata = load_program_metadata(program_id)
            except ValueError as e:
                # åŠ è½½å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯
                updates = [
                    None,
                    None,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    gr.update(visible=False),
                    "",
                    "",
                    "",
                    "",
                    "",
                    0.0,
                    0.0,
                    "",
                    "",
                ]
                for _ in range(MAX_INPUT_FIELDS):
                    updates.append(gr.update(visible=False))
                    updates.append(gr.update(value="", label=""))
                
                gr.Warning(t("run.errors.load_failed").format(error=str(e)))
                return tuple(updates)
            
            # æ„å»ºæ›´æ–°
            input_fields_list = metadata.get('input_fields', [])
            input_descs_list = metadata.get('input_descs', [])
            
            updates = [
                program_id,  # current_program_id
                metadata,  # current_metadata
                gr.update(visible=True),  # program_info_group
                gr.update(visible=True),  # input_section_group
                gr.update(visible=True),  # output_section_group
                metadata.get('signature', ''),  # signature_display
                metadata.get('llm_model', ''),  # model_display
                metadata.get('dspy_module', ''),  # module_display
                metadata.get('teacher_model', ''),  # teacher_display
                metadata.get('optimizer', ''),  # optimizer_display
                metadata.get('evaluation_score', 0.0),  # eval_score_display
                metadata.get('baseline_score', 0.0),  # baseline_score_display
                metadata.get('instructions', ''),  # instructions_display
                metadata.get('optimized_prompt', ''),  # optimized_prompt_display
            ]
            
            # æ›´æ–°è¾“å…¥å­—æ®µ
            for i in range(MAX_INPUT_FIELDS):
                if i < len(input_fields_list):
                    field_name = input_fields_list[i]
                    field_desc = input_descs_list[i] if i < len(input_descs_list) else ""
                    label = f"{field_name}" + (f" ({field_desc})" if field_desc else "")
                    updates.append(gr.update(visible=True))  # input_group
                    updates.append(gr.update(value="", label=label, placeholder=field_desc))  # input_textbox
                else:
                    updates.append(gr.update(visible=False))  # input_group
                    updates.append(gr.update(value="", label=""))  # input_textbox
            
            return tuple(updates)
        
        def run_inference(
            program_id: Optional[str],
            metadata: Optional[Dict[str, Any]],
            history: List[Dict[str, Any]],
            *input_values: str,
        ) -> Tuple[str, Any, Any, List[Dict[str, Any]], Any, Any, Any]:
            """
            æ‰§è¡Œå•æ¡æ¨ç†å¹¶æ›´æ–°å†å²è®°å½•ã€‚
            
            Args:
                program_id: ç¨‹åº ID
                metadata: ç¨‹åºå…ƒæ•°æ®
                history: å½“å‰å†å²è®°å½•åˆ—è¡¨
                *input_values: è¾“å…¥å­—æ®µçš„å€¼
                
            Returns:
                (è¾“å‡ºæ–‡æœ¬, é”™è¯¯æ˜¾ç¤ºæ›´æ–°, åŠ è½½æŒ‡ç¤ºå™¨æ›´æ–°, æ›´æ–°åçš„å†å²è®°å½•,
                 å†å²åˆ—è¡¨æ›´æ–°, ç©ºå†å²æç¤ºæ›´æ–°, å†å²åŒºåŸŸæ›´æ–°)
                 
            Requirements: 2.2, 2.3, 5.1
            """
            if not program_id or not metadata:
                return (
                    "",
                    gr.update(visible=True, value=f"âš ï¸ {t('run.errors.load_failed').format(error='No program selected')}"),
                    gr.update(visible=False),
                    history,
                    gr.update(),  # history_list
                    gr.update(),  # history_empty_msg
                    gr.update(),  # history_section_group
                )
            
            input_fields_list = metadata.get('input_fields', [])
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…å¡«å­—æ®µéƒ½å·²å¡«å†™
            row_data: Dict[str, Any] = {}
            for i, field_name in enumerate(input_fields_list):
                if i < len(input_values):
                    value = input_values[i]
                    if not value or not value.strip():
                        return (
                            "",
                            gr.update(visible=True, value=f"âš ï¸ {t('run.errors.empty_input')}"),
                            gr.update(visible=False),
                            history,
                            gr.update(),
                            gr.update(),
                            gr.update(),
                        )
                    row_data[field_name] = value
                else:
                    return (
                        "",
                        gr.update(visible=True, value=f"âš ï¸ {t('run.errors.empty_input')}"),
                        gr.update(visible=False),
                        history,
                        gr.update(),
                        gr.update(),
                        gr.update(),
                    )
            
            try:
                result = generate_program_response(program_id, row_data)
                
                # æ·»åŠ åˆ°å†å²è®°å½•
                outputs = {"result": result}
                new_history = add_history_item(history, program_id, row_data, outputs)
                
                # æ›´æ–°å†å²åˆ—è¡¨é€‰é¡¹
                choices = get_history_choices(new_history)
                choice_labels = [c[0] for c in choices]
                
                return (
                    result,
                    gr.update(visible=False),
                    gr.update(visible=False),
                    new_history,
                    gr.update(choices=choice_labels, value=None),
                    gr.update(visible=False),  # éšè—ç©ºå†å²æç¤º
                    gr.update(visible=True),  # æ˜¾ç¤ºå†å²åŒºåŸŸ
                )
            except Exception as e:
                error_msg = t("run.errors.inference_failed").format(error=str(e))
                return (
                    "",
                    gr.update(visible=True, value=f"âŒ {error_msg}"),
                    gr.update(visible=False),
                    history,
                    gr.update(),
                    gr.update(),
                    gr.update(),
                )
        
        def clear_inputs(*args) -> Tuple[Any, ...]:
            """æ¸…ç©ºæ‰€æœ‰è¾“å…¥å’Œè¾“å‡º"""
            updates = [""]  # output_display
            updates.append(gr.update(visible=False))  # error_display
            updates.append(gr.update(visible=False))  # loading_indicator
            for _ in range(MAX_INPUT_FIELDS):
                updates.append("")  # input_textbox value
            return tuple(updates)
        
        # === å†å²è®°å½•äº‹ä»¶å¤„ç†å‡½æ•° ===
        
        def on_history_select(
            selection: Optional[str],
            history: List[Dict[str, Any]],
            metadata: Optional[Dict[str, Any]],
        ) -> Tuple[Any, ...]:
            """
            å½“ç”¨æˆ·é€‰æ‹©å†å²è®°å½•é¡¹æ—¶ï¼Œå›å¡«è¾“å…¥å­—æ®µã€‚
            
            Args:
                selection: é€‰ä¸­çš„å†å²è®°å½•æ˜¾ç¤ºæ–‡æœ¬
                history: å†å²è®°å½•åˆ—è¡¨
                metadata: å½“å‰ç¨‹åºå…ƒæ•°æ®
                
            Returns:
                æ›´æ–°è¾“å…¥å­—æ®µçš„å…ƒç»„
                
            Requirements: 5.3
            """
            if not selection or not history or not metadata:
                # è¿”å›ç©ºæ›´æ–°
                updates = []
                for _ in range(MAX_INPUT_FIELDS):
                    updates.append(gr.update())
                return tuple(updates)
            
            # æ ¹æ®é€‰æ‹©æ–‡æœ¬æ‰¾åˆ°å¯¹åº”çš„å†å²è®°å½•ç´¢å¼•
            choices = get_history_choices(history)
            selected_index = None
            for label, idx in choices:
                if label == selection:
                    selected_index = idx
                    break
            
            if selected_index is None or selected_index >= len(history):
                updates = []
                for _ in range(MAX_INPUT_FIELDS):
                    updates.append(gr.update())
                return tuple(updates)
            
            # è·å–å†å²è®°å½•é¡¹
            item_dict = history[selected_index]
            item = InferenceHistoryItem.from_dict(item_dict)
            
            # è·å–è¾“å…¥å­—æ®µåˆ—è¡¨
            input_fields_list = metadata.get('input_fields', [])
            
            # æ„å»ºæ›´æ–°
            updates = []
            for i in range(MAX_INPUT_FIELDS):
                if i < len(input_fields_list):
                    field_name = input_fields_list[i]
                    value = item.inputs.get(field_name, "")
                    updates.append(gr.update(value=value))
                else:
                    updates.append(gr.update())
            
            return tuple(updates)
        
        def on_clear_history() -> Tuple[List[Dict[str, Any]], Any, Any]:
            """
            æ¸…ç©ºå†å²è®°å½•ã€‚
            
            Returns:
                (ç©ºå†å²åˆ—è¡¨, å†å²åˆ—è¡¨æ›´æ–°, ç©ºå†å²æç¤ºæ›´æ–°)
                
            Requirements: 5.4
            """
            gr.Info(t("run.success.history_cleared"))
            return (
                [],  # inference_history
                gr.update(choices=[], value=None),  # history_list
                gr.update(visible=True),  # history_empty_msg
            )
        
        # === æ‰¹é‡å¤„ç†äº‹ä»¶å¤„ç†å‡½æ•° ===
        
        def toggle_mode(
            current_mode_val: str,
            metadata: Optional[Dict[str, Any]],
        ) -> Tuple[Any, ...]:
            """
            åˆ‡æ¢å•æ¡/æ‰¹é‡æ¨¡å¼ã€‚
            
            Args:
                current_mode_val: å½“å‰æ¨¡å¼ ("single" or "batch")
                metadata: ç¨‹åºå…ƒæ•°æ®
                
            Returns:
                æ›´æ–°ç»„ä»¶çš„å…ƒç»„
            """
            if current_mode_val == "single":
                # åˆ‡æ¢åˆ°æ‰¹é‡æ¨¡å¼
                new_mode = "batch"
                btn_text = t("run.mode.switch_to_single")
                show_batch = True
                show_single_input = False
                show_single_output = False
                
                # è·å–æœŸæœ›çš„åˆ—å
                if metadata:
                    input_fields_list = metadata.get('input_fields', [])
                    expected_headers = ", ".join(input_fields_list)
                else:
                    expected_headers = ""
            else:
                # åˆ‡æ¢åˆ°å•æ¡æ¨¡å¼
                new_mode = "single"
                btn_text = t("run.mode.switch_to_batch")
                show_batch = False
                show_single_input = True
                show_single_output = True
                expected_headers = ""
            
            return (
                new_mode,  # current_mode
                gr.update(value=btn_text),  # mode_toggle_btn
                gr.update(visible=show_batch),  # batch_upload_group
                gr.update(visible=show_single_input),  # input_section_group
                gr.update(visible=show_single_output),  # output_section_group
                gr.update(value=expected_headers),  # expected_headers_display
                gr.update(visible=False),  # csv_validation_status
                gr.update(interactive=False),  # start_batch_btn
                None,  # csv_upload (reset)
                gr.update(visible=False),  # batch_results_table
                gr.update(visible=False),  # export_row
                gr.update(visible=False),  # batch_progress
            )
        
        def on_csv_upload(
            file_path: Optional[str],
            metadata: Optional[Dict[str, Any]],
        ) -> Tuple[Any, ...]:
            """
            å¤„ç† CSV æ–‡ä»¶ä¸Šä¼ ï¼ŒéªŒè¯å¤´éƒ¨ã€‚
            
            Args:
                file_path: ä¸Šä¼ çš„ CSV æ–‡ä»¶è·¯å¾„
                metadata: ç¨‹åºå…ƒæ•°æ®
                
            Returns:
                æ›´æ–°ç»„ä»¶çš„å…ƒç»„
            """
            if not file_path or not metadata:
                return (
                    gr.update(visible=False),  # csv_validation_status
                    gr.update(interactive=False),  # start_batch_btn
                )
            
            try:
                # è¯»å– CSV æ–‡ä»¶å¤´éƒ¨
                df = pd.read_csv(file_path, nrows=0)
                csv_headers = list(df.columns)
                
                # è·å–ç¨‹åºçš„è¾“å…¥å­—æ®µ
                input_fields_list = metadata.get('input_fields', [])
                
                # éªŒè¯å¤´éƒ¨
                is_valid, error_msg = validate_csv_headers(csv_headers, input_fields_list)
                
                if is_valid:
                    return (
                        gr.update(
                            visible=True,
                            value=f"âœ… {t('run.batch.completed')}: CSV æ–‡ä»¶éªŒè¯é€šè¿‡"
                        ),  # csv_validation_status
                        gr.update(interactive=True),  # start_batch_btn
                    )
                else:
                    return (
                        gr.update(
                            visible=True,
                            value=f"âŒ {error_msg}"
                        ),  # csv_validation_status
                        gr.update(interactive=False),  # start_batch_btn
                    )
                    
            except Exception as e:
                return (
                    gr.update(
                        visible=True,
                        value=f"âŒ {t('run.errors.csv_upload_failed').format(error=str(e))}"
                    ),  # csv_validation_status
                    gr.update(interactive=False),  # start_batch_btn
                )
        
        def run_batch(
            file_path: Optional[str],
            program_id: Optional[str],
            metadata: Optional[Dict[str, Any]],
            progress: gr.Progress = gr.Progress(),
        ) -> Tuple[Any, ...]:
            """
            æ‰§è¡Œæ‰¹é‡æ¨ç†ã€‚
            
            Args:
                file_path: CSV æ–‡ä»¶è·¯å¾„
                program_id: ç¨‹åº ID
                metadata: ç¨‹åºå…ƒæ•°æ®
                progress: Gradio è¿›åº¦å¯¹è±¡
                
            Returns:
                æ›´æ–°ç»„ä»¶çš„å…ƒç»„
            """
            if not file_path or not program_id or not metadata:
                return (
                    gr.update(visible=True, value="âŒ ç¼ºå°‘å¿…è¦å‚æ•°"),  # batch_progress
                    gr.update(visible=False),  # batch_results_table
                    gr.update(visible=False),  # export_row
                    None,  # batch_result_df
                )
            
            try:
                # è¯»å– CSV æ–‡ä»¶
                df = pd.read_csv(file_path)
                total_rows = len(df)
                
                # å®šä¹‰è¿›åº¦å›è°ƒ
                def progress_callback(current: int, total: int) -> None:
                    progress((current, total), desc=t("run.batch.processing").format(current=current, total=total))
                
                # æ‰§è¡Œæ‰¹é‡æ¨ç†
                result_df = run_batch_inference(
                    program_id,
                    df,
                    progress_callback=progress_callback,
                )
                
                # ç»Ÿè®¡æˆåŠŸ/å¤±è´¥æ•°é‡
                success_count = len(result_df[result_df['_status'] == 'success'])
                error_count = total_rows - success_count
                
                status_msg = f"âœ… {t('run.success.batch_complete').format(count=total_rows)}"
                if error_count > 0:
                    status_msg += f" ({error_count} æ¡å¤±è´¥)"
                
                return (
                    gr.update(visible=True, value=status_msg),  # batch_progress
                    gr.update(visible=True, value=result_df),  # batch_results_table
                    gr.update(visible=True),  # export_row
                    result_df,  # batch_result_df
                )
                
            except Exception as e:
                return (
                    gr.update(visible=True, value=f"âŒ {t('run.errors.inference_failed').format(error=str(e))}"),  # batch_progress
                    gr.update(visible=False),  # batch_results_table
                    gr.update(visible=False),  # export_row
                    None,  # batch_result_df
                )
        
        def export_results(
            result_df: Optional[pd.DataFrame],
            program_id: Optional[str],
        ) -> Any:
            """
            å¯¼å‡ºæ‰¹é‡æ¨ç†ç»“æœä¸º CSV æ–‡ä»¶ã€‚
            
            Args:
                result_df: ç»“æœ DataFrame
                program_id: ç¨‹åº ID
                
            Returns:
                ä¸‹è½½æ–‡ä»¶è·¯å¾„
            """
            if result_df is None or result_df.empty:
                return gr.update(visible=False)
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_dir = tempfile.gettempdir()
            safe_id = program_id.replace(":", "_").replace("/", "_") if program_id else "results"
            file_name = f"{safe_id}_batch_results.csv"
            file_path = os.path.join(temp_dir, file_name)
            
            # ä¿å­˜ CSV
            result_df.to_csv(file_path, index=False, encoding='utf-8-sig')
            
            return gr.update(visible=True, value=file_path)
        
        # === äº‹ä»¶ç»‘å®š ===
        
        # æå–ç»„ä»¶åˆ—è¡¨
        input_group_components = [g for g, t in input_fields]
        input_textbox_components = [t for g, t in input_fields]
        
        # ç¨‹åºé€‰æ‹©è¾“å‡ºç»„ä»¶
        program_select_outputs = [
            current_program_id,
            current_metadata,
            program_info_group,
            input_section_group,
            output_section_group,
            signature_display,
            model_display,
            module_display,
            teacher_display,
            optimizer_display,
            eval_score_display,
            baseline_score_display,
            instructions_display,
            optimized_prompt_display,
        ]
        # æ·»åŠ è¾“å…¥å­—æ®µç»„ä»¶
        for g, tb in input_fields:
            program_select_outputs.append(g)
            program_select_outputs.append(tb)
        
        # åˆ·æ–°æŒ‰é’®
        refresh_btn.click(
            refresh_program_list,
            outputs=[program_dropdown],
        )
        
        # ç¨‹åºé€‰æ‹© - éœ€è¦æ›´æ–°å‡½æ•°ä»¥å¤„ç†æ‰¹é‡åŒºåŸŸå’Œå†å²è®°å½•åŒºåŸŸ
        def on_program_select_with_batch(
            selection: Optional[str],
            history: List[Dict[str, Any]],
        ) -> Tuple[Any, ...]:
            """
            å½“ç”¨æˆ·é€‰æ‹©ç¨‹åºæ—¶åŠ è½½å…ƒæ•°æ®å¹¶æ›´æ–° UIï¼ˆåŒ…æ‹¬æ‰¹é‡åŒºåŸŸå’Œå†å²è®°å½•åŒºåŸŸï¼‰ã€‚
            """
            base_result = on_program_select(selection)
            
            # æ·»åŠ æ‰¹é‡åŒºåŸŸå’Œå†å²è®°å½•åŒºåŸŸçš„æ›´æ–°
            if selection:
                # æ˜¾ç¤ºæ‰¹é‡åŒºåŸŸï¼Œé‡ç½®ä¸ºå•æ¡æ¨¡å¼
                batch_updates = [
                    gr.update(visible=True),  # batch_section_group
                    "single",  # current_mode
                    gr.update(value=t("run.mode.switch_to_batch")),  # mode_toggle_btn
                    gr.update(visible=False),  # batch_upload_group
                ]
                
                # å†å²è®°å½•åŒºåŸŸæ›´æ–°
                if history:
                    choices = get_history_choices(history)
                    choice_labels = [c[0] for c in choices]
                    history_updates = [
                        gr.update(visible=True),  # history_section_group
                        gr.update(choices=choice_labels, value=None),  # history_list
                        gr.update(visible=False),  # history_empty_msg
                    ]
                else:
                    history_updates = [
                        gr.update(visible=True),  # history_section_group
                        gr.update(choices=[], value=None),  # history_list
                        gr.update(visible=True),  # history_empty_msg
                    ]
            else:
                batch_updates = [
                    gr.update(visible=False),  # batch_section_group
                    "single",  # current_mode
                    gr.update(value=t("run.mode.switch_to_batch")),  # mode_toggle_btn
                    gr.update(visible=False),  # batch_upload_group
                ]
                history_updates = [
                    gr.update(visible=False),  # history_section_group
                    gr.update(choices=[], value=None),  # history_list
                    gr.update(visible=True),  # history_empty_msg
                ]
            
            return base_result + tuple(batch_updates) + tuple(history_updates)
        
        # æ›´æ–°ç¨‹åºé€‰æ‹©è¾“å‡ºç»„ä»¶åˆ—è¡¨
        program_select_outputs_with_batch = program_select_outputs + [
            batch_section_group,
            current_mode,
            mode_toggle_btn,
            batch_upload_group,
            history_section_group,
            history_list,
            history_empty_msg,
        ]
        
        program_dropdown.change(
            on_program_select_with_batch,
            inputs=[program_dropdown, inference_history],
            outputs=program_select_outputs_with_batch,
        )
        
        # æ¨¡å¼åˆ‡æ¢æŒ‰é’®
        mode_toggle_btn.click(
            toggle_mode,
            inputs=[current_mode, current_metadata],
            outputs=[
                current_mode,
                mode_toggle_btn,
                batch_upload_group,
                input_section_group,
                output_section_group,
                expected_headers_display,
                csv_validation_status,
                start_batch_btn,
                csv_upload,
                batch_results_table,
                export_row,
                batch_progress,
            ],
        )
        
        # CSV ä¸Šä¼ éªŒè¯
        csv_upload.change(
            on_csv_upload,
            inputs=[csv_upload, current_metadata],
            outputs=[csv_validation_status, start_batch_btn],
        )
        
        # å¼€å§‹æ‰¹é‡æ¨ç†
        start_batch_btn.click(
            run_batch,
            inputs=[csv_upload, current_program_id, current_metadata],
            outputs=[batch_progress, batch_results_table, export_row, batch_result_df],
        )
        
        # å¯¼å‡ºç»“æœ
        export_btn.click(
            export_results,
            inputs=[batch_result_df, current_program_id],
            outputs=[download_file],
        )
        
        # è¿è¡ŒæŒ‰é’® - å…ˆæ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨ï¼Œç„¶åæ‰§è¡Œæ¨ç†
        def show_loading():
            """æ˜¾ç¤ºåŠ è½½æŒ‡ç¤ºå™¨"""
            return gr.update(visible=True), gr.update(interactive=False)
        
        run_btn.click(
            show_loading,
            outputs=[loading_indicator, run_btn],
        ).then(
            run_inference,
            inputs=[current_program_id, current_metadata, inference_history] + input_textbox_components,
            outputs=[
                output_display,
                error_display,
                loading_indicator,
                inference_history,
                history_list,
                history_empty_msg,
                history_section_group,
            ],
        ).then(
            lambda: gr.update(interactive=True),
            outputs=[run_btn],
        )
        
        # æ¸…ç©ºæŒ‰é’®
        clear_outputs = [output_display, error_display, loading_indicator] + input_textbox_components
        clear_btn.click(
            clear_inputs,
            outputs=clear_outputs,
        )
        
        # å†å²è®°å½•é€‰æ‹© - å›å¡«è¾“å…¥
        history_list.change(
            on_history_select,
            inputs=[history_list, inference_history, current_metadata],
            outputs=input_textbox_components,
        )
        
        # æ¸…ç©ºå†å²æŒ‰é’®
        clear_history_btn.click(
            on_clear_history,
            outputs=[inference_history, history_list, history_empty_msg],
        )
        
        # é¡µé¢åŠ è½½æ—¶åˆ·æ–°ç¨‹åºåˆ—è¡¨
        program_dropdown.render = lambda: refresh_program_list()
